ğŸš€ LangChain Translation API

A simple LLM-powered Translation API built using FastAPI + LangChain (LCEL) + Groq (Llama 3.1).
This project demonstrates how to create a production-style AI API server using modern GenAI tools.

ğŸ“Œ Features

ğŸŒ Translate text into any language

âš¡ Fast inference using Groq LLM (Llama 3.1)

ğŸ”— LangChain LCEL pipeline (Prompt â†’ Model â†’ Parser)

ğŸš€ FastAPI backend with LangServe routes

ğŸ“¡ REST API ready (/chain/invoke)

ğŸ§  Clean modular chain architecture

ğŸ” Environment variable based secret handling

ğŸ›  Tech Stack

Python

FastAPI

LangChain (LCEL)

Groq LLM (Llama 3.1)

LangServe

Uvicorn

python-dotenv

ğŸ“‚ Project Structure
langchain-translation-api/
â”‚
â”œâ”€â”€ serve.py              # FastAPI + LangChain server
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ .env                  # API keys (not pushed to GitHub)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
âš™ï¸ Setup & Run Locally
1ï¸âƒ£ Clone repo
git clone https://github.com/YOUR_USERNAME/langchain-translation-api.git
cd langchain-translation-api
2ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate     # Windows
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
4ï¸âƒ£ Create .env

Create .env file:

GROQ_API_KEY=your_groq_api_key_here

âš ï¸ Never share .env publicly.

5ï¸âƒ£ Run server
python serve.py

Server will start at:

http://localhost:8000
ğŸ§ª Test API

Open Swagger UI:

http://localhost:8000/docs

Use endpoint:

POST /chain/invoke

Request body:

{
  "input": {
    "language": "French",
    "text": "Hello, how are you?"
  }
}
ğŸ”„ API Flow
User Input â†’ Prompt Template â†’ Groq LLM â†’ Output Parser â†’ API Response
ğŸ” Security
API keys stored in .env

.env excluded via .gitignore

No secrets committed to repository

Output can be see in postman api also. 


Open:

http://localhost:8000/docs

Use endpoint:

POST /chain/invoke

Body:

{
  "input": {
    "language": "French",
    "text": "Hello, how are you?"
  }
}
